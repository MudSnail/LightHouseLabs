{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc80ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to demontstarte, we will generate original values/predictions\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ae8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate 10 observations/predictions (y_true and y_pred) from a model\n",
    "\n",
    "#generate 'ground truth'\n",
    "y_true = np.random.normal(0,1,10)\n",
    "\n",
    "#generate random errors\n",
    "errors = np.random.normal(0,0.02,10)\n",
    "\n",
    "#stimulate predicitions\n",
    "y_pred = y_true + errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86eaf62",
   "metadata": {},
   "source": [
    "## MSE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbd797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004925790320259297\n"
     ]
    }
   ],
   "source": [
    "#import MSE from sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#compute MSE\n",
    "MSE = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc52b3cf",
   "metadata": {},
   "source": [
    "the module first takes the ground truths and then our prediction\n",
    "\n",
    "to get RMSE from MSE, we can either:\n",
    "\n",
    "    compute the square root of MSE\n",
    "    use the squared=False option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c810807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022194121564638004\n",
      "0.022194121564638004\n"
     ]
    }
   ],
   "source": [
    "#RMSE bu numpy\n",
    "RMSE = np.sqrt(MSE)\n",
    "print(RMSE)\n",
    "\n",
    "#RMSE bu sklearn\n",
    "RMSE = mean_squared_error(y_true, y_pred, squared = False)\n",
    "print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e10113",
   "metadata": {},
   "source": [
    "## Classification models Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee33490",
   "metadata": {},
   "source": [
    "Same preciple as last example, but we need predicited probabilities instead of predicted labels (predicted values of regresssion)\n",
    "\n",
    "We will stimulate a binary classifier. Meaning the predicted class can only be positive (1) or negative (0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "962ec0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "y_true = [1,1,0,1,0,0,1,0,0,1]\n",
    "\n",
    "# simulate probabilites of positive class\n",
    "y_proba = [0.9,0.7,0.2,0.99,0.7,0.1,0.5,0.2,0.4,0.6]\n",
    "\n",
    "# set the threshold to predict positive class\n",
    "thres = 0.5\n",
    "\n",
    "# class predictions\n",
    "y_pred = [int(value > thres) for value in y_proba]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ded0e5",
   "metadata": {},
   "source": [
    "in y_proba we have the probabilities of observations from positive class. We also set the threshold level. All obersvations with probabilities above this threshold are assigned to the positive class and stored in the u_pred variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f327337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 1, 1, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c47f9",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0409086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# import accuracy_score from sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# compute accuracy\n",
    "accuracy = accuracy_score(y_true,y_pred)\n",
    "\n",
    "# print accuracy\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2e3af",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f8a64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8000000000000002\n"
     ]
    }
   ],
   "source": [
    "# import f1_score from sklearn\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# compute F1-score\n",
    "f1_score = f1_score(y_true,y_pred)\n",
    "\n",
    "# print F1-score\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0cbd98",
   "metadata": {},
   "source": [
    "### AUC SCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c059d1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "# import roc_auc_score from sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# compute AUC-score\n",
    "auc = roc_auc_score(y_true,y_proba)\n",
    "\n",
    "# print AUC-score\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89f5d1",
   "metadata": {},
   "source": [
    "In roc_auc_score we use probabilities (y_proba) instead of class labels. If we passed class labels no errors would be shown but the score would be inaccurate. Be careful and read the documentation before using Sklearn functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c322ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LHLBootcamp",
   "language": "python",
   "name": "lhlbootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
